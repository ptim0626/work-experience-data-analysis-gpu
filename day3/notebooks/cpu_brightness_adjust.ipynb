{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27572d2f-1ea0-4d5c-9e68-a88a31318a00",
   "metadata": {},
   "source": [
    "# Brightness Adjustment - CPU Kernel Operation for Images\n",
    "This script demonstrates a basic concept of image processing - adjust the brightness of each pixel in an image.\n",
    "\n",
    "Brightness adjustment is one of the simplest image processing operations - we add a constant value to every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92acef-1199-400e-ad56-47b604bdddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58afbaaf-5897-47da-bef6-584d35b7d469",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4524c-076a-447d-9e92-c54098c1e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a small test image with gradient pattern\n",
    "rows, cols = 6, 8\n",
    "test_image = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "# fill with gradient from dark (top-left) to bright (bottom-right)\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        test_image[r, c] = (r * cols + c) * 4  \n",
    "\n",
    "print(f\"Test image ({rows}Ã—{cols}):\")\n",
    "print(test_image)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.matshow(test_image, cmap='gray', vmin=0, vmax=255)\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e67ba9-df90-4591-aa14-6c99c2bdec28",
   "metadata": {},
   "source": [
    "## Sequential Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17448fc3-3d29-4610-8e8f-ec6bb3726a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness_sequential(image, brightness_offset):\n",
    "    \"\"\"\n",
    "    Sequential implementation processes one pixel at a time.\n",
    "    This demonstrates how a CPU would execute the kernel.\n",
    "    This includes clamping to valid range [0, 255] for 8-bit images.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols = image.shape\n",
    "    result = np.zeros((num_rows, num_cols), dtype=np.float32)\n",
    "    \n",
    "    # process each pixel individually\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            # apply the kernel function to pixel at (row, col)\n",
    "            new_value = image[row, col] + brightness_offset\n",
    "            \n",
    "            # clamp to valid range\n",
    "            if new_value < 0:\n",
    "                new_value = 0\n",
    "            elif new_value > 255:\n",
    "                new_value = 255\n",
    "                \n",
    "            result[row, col] = new_value\n",
    "   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a4505-9665-426c-b9e6-2ed668c28fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_offset = 50.0\n",
    "result = adjust_brightness_sequential(test_image, brightness_offset)\n",
    "\n",
    "# visualise input and output\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "im1 = ax1.matshow(test_image, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title(f\"Original Image\")\n",
    "ax1.set_xlabel(\"Column\")\n",
    "ax1.set_ylabel(\"Row\")\n",
    "plt.colorbar(im1, ax=ax1, fraction=0.046)\n",
    "\n",
    "im2 = ax2.matshow(result, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title(f\"Brightness +{int(brightness_offset)}\")\n",
    "ax2.set_xlabel(\"Column\")\n",
    "ax2.set_ylabel(\"Row\")\n",
    "plt.colorbar(im2, ax=ax2, fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOriginal image:\")\n",
    "print(test_image)\n",
    "print(f\"\\nAfter brightness adjustment:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6f1f8-9466-4b11-84d6-f65d7fef8f60",
   "metadata": {},
   "source": [
    "## Simulating Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9994b53-46de-4716-9fcc-e159a170b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_parallel_processing_2d(image, brightness_offset, block_shape=(2, 2)):\n",
    "    \"\"\"\n",
    "    Simulates how parallel processing would work on a GPU.\n",
    "    Each thread block processes a portion of the image independently.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols = image.shape\n",
    "    block_rows, block_cols = block_shape\n",
    "    \n",
    "    # calculate grid dimensions\n",
    "    grid_rows = (num_rows + block_rows - 1) // block_rows\n",
    "    grid_cols = (num_cols + block_cols - 1) // block_cols\n",
    "    \n",
    "    result = np.zeros_like(image)\n",
    "    block_assignments = []\n",
    "    \n",
    "    # simulate each thread block processing its region\n",
    "    for block_y in range(grid_rows):\n",
    "        for block_x in range(grid_cols):\n",
    "            # calculate which pixels this block processes\n",
    "            start_row = block_y * block_rows\n",
    "            end_row = min(start_row + block_rows, num_rows)\n",
    "            start_col = block_x * block_cols\n",
    "            end_col = min(start_col + block_cols, num_cols)\n",
    "            \n",
    "            # record assignment for visualisation\n",
    "            block_assignments.append(((block_y, block_x), \n",
    "                                     (start_row, end_row), \n",
    "                                     (start_col, end_col)))\n",
    "            \n",
    "            # process this block's pixels\n",
    "            for row in range(start_row, end_row):\n",
    "                for col in range(start_col, end_col):\n",
    "                    new_value = image[row, col] + brightness_offset\n",
    "                    # clamp\n",
    "                    if new_value < 0:\n",
    "                        new_value = 0\n",
    "                    elif new_value > 255:\n",
    "                        new_value = 255\n",
    "                    result[row, col] = new_value\n",
    "    \n",
    "    return result, block_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a2000-5a0d-417e-a729-160f0f14e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parallel, assignments = simulate_parallel_processing_2d(\n",
    "    test_image, brightness_offset, block_shape=(3, 4)\n",
    ")\n",
    "\n",
    "print(f\"Using {len(assignments)} thread blocks:\")\n",
    "for (block_y, block_x), (sr, er), (sc, ec) in assignments:\n",
    "    print(f\"  Block ({block_y},{block_x}): processes pixels \"\n",
    "          f\"rows {sr}-{er-1}, cols {sc}-{ec-1}\")\n",
    "\n",
    "# verify results match\n",
    "print(f\"\\nResults match sequential: {np.allclose(result, result_parallel)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e127c72-52f2-40f6-ac59-4742bc9069bc",
   "metadata": {},
   "source": [
    "## Visualise Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5905a3-b1d2-4242-99e9-54dde346581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_processing_2d(image_shape=(8, 12), block_shape=(4, 4)):\n",
    "    \"\"\"Create a visual representation of sequential vs parallel processing for 2D images.\"\"\"\n",
    "    rows, cols = image_shape\n",
    "    block_rows, block_cols = block_shape\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # sequential processing visualisation\n",
    "    ax1.set_title(\"Sequential Processing (CPU)\", fontsize=14)\n",
    "    ax1.set_xlim(-0.5, cols - 0.5)\n",
    "    ax1.set_ylim(-0.5, rows - 0.5)\n",
    "    ax1.set_xlabel(\"Column\")\n",
    "    ax1.set_ylabel(\"Row\")\n",
    "\n",
    "    # match image coordinates\n",
    "    ax1.invert_yaxis()  \n",
    "    \n",
    "    # create gradient showing processing order\n",
    "    sequential_order = np.zeros((rows, cols))\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            sequential_order[r, c] = r * cols + c\n",
    "    \n",
    "    im1 = ax1.matshow(sequential_order, cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    # add zig-zag arrows showing sequential row-major flow\n",
    "    arrow_props = dict(arrowstyle='->', color='red', lw=2)\n",
    "    \n",
    "    for r in range(rows):\n",
    "        # each row processes left to right\n",
    "        if cols > 1:  \n",
    "            # only add arrow if there are multiple columns\n",
    "            ax1.annotate('', xy=(cols-1, r), xytext=(0, r),\n",
    "                         arrowprops=arrow_props)\n",
    "        \n",
    "        # connect last pixel of current row to first pixel of next row\n",
    "        if r < rows - 1:\n",
    "            ax1.annotate('', xy=(0, r+1), xytext=(cols-1, r),\n",
    "                         arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "    \n",
    "    ax1.text(cols/2, rows + 0.3, 'Processes pixels in row-major order',\n",
    "             ha='center', color='red', fontsize=12, weight='bold',\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "    \n",
    "    # parallel processing visualisation\n",
    "    ax2.set_title(\"Parallel Processing (GPU)\", fontsize=14)\n",
    "    ax2.set_xlim(-0.5, cols - 0.5)\n",
    "    ax2.set_ylim(-0.5, rows - 0.5)\n",
    "    ax2.set_xlabel(\"Column\")\n",
    "    ax2.set_ylabel(\"Row\")\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    # calculate grid\n",
    "    grid_rows = (rows + block_rows - 1) // block_rows\n",
    "    grid_cols = (cols + block_cols - 1) // block_cols\n",
    "    \n",
    "    # colour map for blocks\n",
    "    colours = plt.cm.Set3(np.linspace(0, 1, grid_rows * grid_cols))\n",
    "    \n",
    "    # show blocks\n",
    "    block_id = 0\n",
    "    for br in range(grid_rows):\n",
    "        for bc in range(grid_cols):\n",
    "            start_row = br * block_rows\n",
    "            end_row = min(start_row + block_rows, rows)\n",
    "            start_col = bc * block_cols\n",
    "            end_col = min(start_col + block_cols, cols)\n",
    "            \n",
    "            # create block patch\n",
    "            block_array = np.ones((end_row - start_row, end_col - start_col))\n",
    "            block_extent = [start_col - 0.5, end_col - 0.5, \n",
    "                           end_row - 0.5, start_row - 0.5]\n",
    "            \n",
    "            ax2.imshow(block_array, extent=block_extent,\n",
    "                      cmap='gray', vmin=0, vmax=2,\n",
    "                      alpha=0)\n",
    "            \n",
    "            # draw block boundary\n",
    "            rect = plt.Rectangle((start_col - 0.5, start_row - 0.5),\n",
    "                               end_col - start_col, end_row - start_row,\n",
    "                               fill=False, edgecolor=colours[block_id],\n",
    "                               linewidth=3)\n",
    "            ax2.add_patch(rect)\n",
    "            \n",
    "            # label the block\n",
    "            block_center_x = (start_col + end_col - 1) / 2\n",
    "            block_center_y = (start_row + end_row - 1) / 2\n",
    "            ax2.text(block_center_x, block_center_y,\n",
    "                    f\"Block\\n({br},{bc})\",\n",
    "                    ha='center', va='center', fontsize=10,\n",
    "                    weight='bold', color=colours[block_id])\n",
    "            \n",
    "            block_id += 1\n",
    "    \n",
    "    ax2.text(cols/2, -1.5, \n",
    "            'All blocks process simultaneously',\n",
    "            ha='center', color='green', fontsize=12, weight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # add grid lines\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_xticks(range(cols))\n",
    "        ax.set_yticks(range(rows))\n",
    "        ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fabb0-c6c4-4909-bcfd-ded233e3b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_processing_2d(image_shape=(8, 12), block_shape=(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a152e-9eab-48a8-b52b-35f3cb8198bf",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdc25b-064d-4b91-b34c-4ae1d398da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_implementations(sizes):\n",
    "    \"\"\"Compare performance of sequential and vectorised implementations.\"\"\"\n",
    "    results = {\n",
    "        \"sequential\": [],\n",
    "        \"vectorised\": [],\n",
    "        \"sizes\": sizes\n",
    "    }\n",
    "    brightness_offset = 75.0\n",
    "    \n",
    "    print(\"\\nPerformance Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Image Size':>15} {'Sequential':>12} {'Vectorised':>12} {'Speed-up':>12}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    for size in sizes:\n",
    "        # create test image\n",
    "        image = rng.integers(0, 200, size=(size, size), dtype=np.uint8).astype(np.float32)\n",
    "        \n",
    "        # sequential implementation\n",
    "        start = time.perf_counter()\n",
    "        result_seq = adjust_brightness_sequential(image, brightness_offset)\n",
    "        time_seq = time.perf_counter() - start\n",
    "        results[\"sequential\"].append(time_seq)\n",
    "        \n",
    "        # vectorised implementation with clamping\n",
    "        start = time.perf_counter()\n",
    "        result_vec = image + brightness_offset\n",
    "        result_vec = np.clip(result_vec, 0, 255)\n",
    "        time_vec = time.perf_counter() - start\n",
    "        results[\"vectorised\"].append(time_vec)\n",
    "        \n",
    "        # verify results match\n",
    "        assert np.allclose(result_seq, result_vec)\n",
    "        \n",
    "        print(f\"{size:>4}   x   {size:<4} {time_seq:>12.6f} {time_vec:>12.6f} {time_seq/time_vec:>12.2f}x\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebbad7-2223-47f5-92b1-43609f657a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [32, 64, 128, 256, 512]\n",
    "results = benchmark_implementations(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ccc5d4-9ff1-482e-9a24-93c278ad3dea",
   "metadata": {},
   "source": [
    "## Demonstrating Clamping Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842e893-f6a0-4e57-80ce-106d5e2713e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test image with extreme values to show clamping\n",
    "extreme_image = np.array([\n",
    "    [5,   10,  20,  30],    # very dark pixels\n",
    "    [50,  100, 150, 200],   # medium pixels\n",
    "    [210, 220, 230, 240],   # bright pixels  \n",
    "    [245, 250, 253, 255]    # very bright pixels\n",
    "], dtype=np.float32)\n",
    "\n",
    "# test with large positive offset\n",
    "bright_offset = 100\n",
    "brightened = adjust_brightness_sequential(extreme_image, bright_offset)\n",
    "\n",
    "# test with negative offset\n",
    "dark_offset = -100\n",
    "darkened = adjust_brightness_sequential(extreme_image, dark_offset)\n",
    "\n",
    "print(\"Demonstrating clamping behaviour:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOriginal image:\")\n",
    "print(extreme_image)\n",
    "\n",
    "print(f\"\\nAfter brightness +{bright_offset}:\")\n",
    "print(brightened)\n",
    "print(\"Note: Values clamped at 255\")\n",
    "\n",
    "print(f\"\\nAfter brightness {dark_offset}:\")\n",
    "print(darkened)\n",
    "print(\"Note: Values clamped at 0\")\n",
    "\n",
    "# visualise clamping\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "im1 = ax[0].matshow(extreme_image, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0].set_title(\"Original\")\n",
    "plt.colorbar(im1, ax=ax[0], fraction=0.046)\n",
    "\n",
    "im2 = ax[1].matshow(brightened, cmap='gray', vmin=0, vmax=255)\n",
    "ax[1].set_title(f\"Brightness +{bright_offset}\")\n",
    "plt.colorbar(im2, ax=ax[1], fraction=0.046)\n",
    "\n",
    "im3 = ax[2].matshow(darkened, cmap='gray', vmin=0, vmax=255)\n",
    "ax[2].set_title(f\"Brightness {dark_offset}\")\n",
    "plt.colorbar(im3, ax=ax[2], fraction=0.046)\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Column\")\n",
    "    a.set_ylabel(\"Row\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc84c1-297f-41a9-87d7-4244e9c648a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
